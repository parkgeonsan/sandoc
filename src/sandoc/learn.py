"""
sandoc.learn â€” ì§€ì‹ ì¶•ì  (Knowledge Accumulation)

ì™„ì„±ëœ ì´ˆì•ˆ ì„¹ì…˜ì—ì„œ:
  - íš¨ê³¼ì ì¸ í‘œí˜„/íŒ¨í„´ ì¶”ì¶œ
  - knowledge/expressions/ ì— ì €ì¥
  - knowledge/patterns/ ì— ì €ì¥
  - knowledge/lessons.md ì— ê¸°ë¡
  - ì²˜ë¦¬ëœ ê³µê³  ìœ í˜• ì¶”ì 
"""

from __future__ import annotations

import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

# â”€â”€ ì„¹ì…˜ í‚¤ â†’ í‰ê°€ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SECTION_CATEGORY_MAP = {
    "company_overview": "ê¸°ì—…ê°œìš”",
    "problem_recognition": "ë¬¸ì œì¸ì‹",
    "solution": "ì‹¤í˜„ê°€ëŠ¥ì„±",
    "business_model": "ì‹¤í˜„ê°€ëŠ¥ì„±",
    "market_analysis": "ì„±ì¥ì „ëµ",
    "growth_strategy": "ì„±ì¥ì „ëµ",
    "team": "íŒ€êµ¬ì„±",
    "financial_plan": "ì¬ë¬´ê³„íš",
    "funding_plan": "ì¬ë¬´ê³„íš",
}

# íš¨ê³¼ì  í‘œí˜„ ì¶”ì¶œ íŒ¨í„´
EXPRESSION_PATTERNS = [
    # ìˆ˜ì¹˜ê°€ í¬í•¨ëœ êµ¬ì²´ì  ì„±ê³¼ í‘œí˜„
    (r"[ê°€-í£\w]+\s*\d[\d,.]*\s*[%ì–µë§Œì›ê±´ëª…ê°œí˜¸ëŒ€]+\s*(?:ì´ìƒ|ë‹¬ì„±|ì¦ê°€|ê°ì†Œ|ì ˆê°|í™•ë³´|ìœ ì¹˜|ëŒíŒŒ)", "ì„±ê³¼_ìˆ˜ì¹˜"),
    # ë¹„êµ ìš°ìœ„ í‘œí˜„
    (r"ê¸°ì¡´\s*ëŒ€ë¹„\s*\d[\d,.]*\s*[%ë°°]+\s*[ê°€-í£]+", "ë¹„êµìš°ìœ„"),
    # ì—°ë„ë³„ ëª©í‘œ í‘œí˜„
    (r"\d{4}ë…„?\s*[:ï¼š]?\s*[ê°€-í£\w,\s]+(?:ë‹¬ì„±|ëª©í‘œ|ì‹œì‘|ë¡ ì¹­|í™•ëŒ€)", "ì—°ë„ë³„ëª©í‘œ"),
    # í•µì‹¬ ì°¨ë³„ì  í‘œí˜„ (â‘ â‘¡â‘¢ í˜•íƒœ)
    (r"[â‘ â‘¡â‘¢â‘£â‘¤]\s*[ê°€-í£\w\s]+(?:\([^)]+\))?", "ì°¨ë³„ì ì—´ê±°"),
]

# êµ¬ì¡°ì  íŒ¨í„´ ìœ í˜•
STRUCTURE_PATTERNS = [
    ("table", r"\|[^|]+\|[^|]+\|", "í‘œ í˜•ì‹ ë°ì´í„° ì œì‹œ"),
    ("bullet_hierarchy", r"â—¦\s*.+\n\s+-\s+", "ë¶ˆë¦¿ ê³„ì¸µ êµ¬ì¡°"),
    ("numbered_list", r"\d+\.\s+.+(?:\n\s+.+)*", "ë²ˆí˜¸ ëª©ë¡ êµ¬ì¡°"),
    ("section_header", r"â–¡\s+.+|[0-9]+-[0-9]+[-.]?\s+", "ì„¹ì…˜ í—¤ë” êµ¬ì¡°"),
]


def run_learn(
    project_dir: Path,
    knowledge_dir: Path | None = None,
) -> dict[str, Any]:
    """
    ì™„ì„±ëœ ì´ˆì•ˆì—ì„œ ì§€ì‹ì„ ì¶•ì í•©ë‹ˆë‹¤.

    Args:
        project_dir: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        knowledge_dir: ì§€ì‹ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: project_dir ê¸°ì¤€ ìƒìœ„ knowledge/)

    Returns:
        {
            "success": bool,
            "expressions_count": int,
            "patterns_count": int,
            "lessons_path": str,
            "processed_sections": list[str],
            "errors": list[str],
        }
    """
    result: dict[str, Any] = {
        "success": False,
        "expressions_count": 0,
        "patterns_count": 0,
        "lessons_path": None,
        "processed_sections": [],
        "errors": [],
    }

    # ì´ˆì•ˆ ë””ë ‰í† ë¦¬ íƒìƒ‰
    drafts_dir = project_dir / "output" / "drafts" / "current"
    if not drafts_dir.is_dir():
        result["errors"].append(
            f"ì´ˆì•ˆ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {drafts_dir}\n"
            "ë¨¼ì € ì„¹ì…˜ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”."
        )
        return result

    md_files = sorted(drafts_dir.glob("*.md"))
    if not md_files:
        result["errors"].append("ì´ˆì•ˆ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return result

    # ì§€ì‹ ë””ë ‰í† ë¦¬ ê²°ì •
    if knowledge_dir is None:
        # í”„ë¡œì íŠ¸ ìƒìœ„ì— knowledge/ ì‚¬ìš© (ì „ì—­ ì§€ì‹ ì €ì¥ì†Œ)
        knowledge_dir = project_dir.parent.parent / "knowledge"
        if not knowledge_dir.exists():
            knowledge_dir = project_dir / "knowledge"

    expressions_dir = knowledge_dir / "expressions"
    patterns_dir = knowledge_dir / "patterns"
    expressions_dir.mkdir(parents=True, exist_ok=True)
    patterns_dir.mkdir(parents=True, exist_ok=True)

    # í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ
    project_name = project_dir.name
    context_path = project_dir / "context.json"
    announcement_type = "unknown"
    if context_path.exists():
        try:
            ctx = json.loads(context_path.read_text(encoding="utf-8"))
            project_name = ctx.get("project_name", project_name)
            aa = ctx.get("announcement_analysis", {})
            if aa:
                announcement_type = aa.get("title", "unknown")[:50]
        except (json.JSONDecodeError, OSError):
            pass

    # ê° ì„¹ì…˜ ì²˜ë¦¬
    all_expressions: list[dict[str, str]] = []
    all_patterns: list[dict[str, str]] = []
    sections_processed: list[str] = []
    lessons: list[str] = []

    for md_path in md_files:
        content = md_path.read_text(encoding="utf-8")
        if not content.strip():
            continue

        section_stem = md_path.stem
        # ì„¹ì…˜ í‚¤ ì¶”ì¶œ (01_company_overview â†’ company_overview)
        section_key = re.sub(r"^\d+_", "", section_stem)
        category = SECTION_CATEGORY_MAP.get(section_key, "ê¸°íƒ€")

        # 1. í‘œí˜„ ì¶”ì¶œ
        expressions = _extract_expressions(content, section_key, category)
        all_expressions.extend(expressions)

        # 2. êµ¬ì¡° íŒ¨í„´ ì¶”ì¶œ
        patterns = _extract_patterns(content, section_key, category)
        all_patterns.extend(patterns)

        # 3. êµí›ˆ ì¶”ì¶œ
        lesson = _extract_lesson(content, section_key, category)
        if lesson:
            lessons.append(lesson)

        sections_processed.append(section_key)

    # â”€â”€ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. í‘œí˜„ ì €ì¥
    if all_expressions:
        expr_path = expressions_dir / f"{project_name}_{timestamp}.json"
        expr_path.write_text(
            json.dumps(all_expressions, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        result["expressions_count"] = len(all_expressions)

    # 2. íŒ¨í„´ ì €ì¥
    if all_patterns:
        pat_path = patterns_dir / f"{project_name}_{timestamp}.json"
        pat_path.write_text(
            json.dumps(all_patterns, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        result["patterns_count"] = len(all_patterns)

    # 3. êµí›ˆ ê¸°ë¡
    lessons_path = knowledge_dir / "lessons.md"
    _append_lessons(lessons_path, project_name, announcement_type, lessons, timestamp)
    result["lessons_path"] = str(lessons_path)

    # 4. ì²˜ë¦¬ ì´ë ¥ ê¸°ë¡
    _record_processed(knowledge_dir, project_name, announcement_type, timestamp)

    result["success"] = True
    result["processed_sections"] = sections_processed
    return result


def _extract_expressions(
    content: str, section_key: str, category: str
) -> list[dict[str, str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ íš¨ê³¼ì ì¸ í‘œí˜„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    expressions: list[dict[str, str]] = []

    for pattern, expr_type in EXPRESSION_PATTERNS:
        for match in re.finditer(pattern, content):
            text = match.group().strip()
            if len(text) > 10:  # ë„ˆë¬´ ì§§ì€ ê±´ ìŠ¤í‚µ
                expressions.append({
                    "text": text,
                    "type": expr_type,
                    "section": section_key,
                    "category": category,
                })

    return expressions


def _extract_patterns(
    content: str, section_key: str, category: str
) -> list[dict[str, str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°ì  íŒ¨í„´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    patterns: list[dict[str, str]] = []

    for pat_type, regex, description in STRUCTURE_PATTERNS:
        matches = re.findall(regex, content)
        if matches:
            patterns.append({
                "type": pat_type,
                "description": description,
                "section": section_key,
                "category": category,
                "count": str(len(matches)),
                "sample": matches[0][:100] if matches else "",
            })

    return patterns


def _extract_lesson(content: str, section_key: str, category: str) -> str | None:
    """ì„¹ì…˜ ë‚´ìš©ì—ì„œ êµí›ˆ/íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    char_count = len(content)
    table_count = content.count("|---|")
    bullet_count = content.count("â—¦")
    numbered_count = len(re.findall(r"^\d+\.", content, re.MULTILINE))

    # ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ë§Œ
    if char_count < 100:
        return None

    parts = []
    parts.append(f"- **{section_key}** ({category}): {char_count}ì")
    if table_count:
        parts.append(f"  í‘œ {table_count}ê°œ ì‚¬ìš©")
    if bullet_count > 3:
        parts.append(f"  ë¶ˆë¦¿ {bullet_count}ê°œë¡œ êµ¬ì¡°í™”")
    if numbered_count > 2:
        parts.append(f"  ë²ˆí˜¸ ëª©ë¡ {numbered_count}ê°œ ì‚¬ìš©")

    return ", ".join(parts)


def _append_lessons(
    lessons_path: Path,
    project_name: str,
    announcement_type: str,
    lessons: list[str],
    timestamp: str,
) -> None:
    """lessons.md ì— êµí›ˆì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    header = (
        f"\n## {project_name} ({timestamp})\n"
        f"ê³µê³  ìœ í˜•: {announcement_type}\n\n"
    )

    content = header
    if lessons:
        for lesson in lessons:
            content += f"{lesson}\n"
    else:
        content += "- íŠ¹ë³„í•œ êµí›ˆ ì—†ìŒ\n"
    content += "\n"

    # ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€
    if lessons_path.exists():
        existing = lessons_path.read_text(encoding="utf-8")
    else:
        existing = "# ğŸ“š sandoc í•™ìŠµ ê¸°ë¡ (Lessons Learned)\n\n"

    lessons_path.write_text(existing + content, encoding="utf-8")


def _record_processed(
    knowledge_dir: Path,
    project_name: str,
    announcement_type: str,
    timestamp: str,
) -> None:
    """ì²˜ë¦¬ ì´ë ¥ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
    history_path = knowledge_dir / "processing_history.json"
    history: list[dict[str, str]] = []

    if history_path.exists():
        try:
            history = json.loads(history_path.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            history = []

    history.append({
        "project": project_name,
        "announcement_type": announcement_type,
        "processed_at": timestamp,
    })

    history_path.write_text(
        json.dumps(history, ensure_ascii=False, indent=2), encoding="utf-8"
    )
